{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day8_Practice_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFLDaFe4Wm3ewBIdDPJSDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIA-khm/basemodel/blob/master/0.%20Tutorial/AI_intro/Day8_Practice_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD4gfURR4Qva"
      },
      "source": [
        "# function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "E7J8S0Ct4QhO",
        "outputId": "fa3e1b16-5b4d-4cd4-d3f7-e657dbc0da57"
      },
      "source": [
        "\"\"\"\n",
        "import sys, os\n",
        "import numpy as np\n",
        "\n",
        "def numerical_gradient(f,x):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
        "\n",
        "  for idx in range(x.size):\n",
        "    tmp_val = x[idx]\n",
        "    # f(x+h) 계산\n",
        "    x[idx] = tmp_val + h\n",
        "    fxh1 = f(x)\n",
        "\n",
        "    # f(x-h) 계산\n",
        "    x[idx] = tmp_val - h\n",
        "    fxh2 = f(x)\n",
        "\n",
        "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "    x[idx] = tmp_val # 값 복원\n",
        "\n",
        "  return grad\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x)) \n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport sys, os\\nimport numpy as np\\n\\ndef numerical_gradient(f,x):\\n  h = 1e-4\\n  grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\\n\\n  for idx in range(x.size):\\n    tmp_val = x[idx]\\n    # f(x+h) 계산\\n    x[idx] = tmp_val + h\\n    fxh1 = f(x)\\n\\n    # f(x-h) 계산\\n    x[idx] = tmp_val - h\\n    fxh2 = f(x)\\n\\n    grad[idx] = (fxh1 - fxh2) / (2*h)\\n    x[idx] = tmp_val # 값 복원\\n\\n  return grad\\n\\ndef sigmoid(x):\\n  return 1 / (1 + np.exp(-x)) \\n\\ndef softmax(x):\\n    if x.ndim == 2:\\n        x = x.T\\n        x = x - np.max(x, axis=0)\\n        y = np.exp(x) / np.sum(np.exp(x), axis=0)\\n        return y.T \\n\\n    x = x - np.max(x) # 오버플로 대책\\n    return np.exp(x) / np.sum(np.exp(x))\\n\\n\\ndef cross_entropy_error(y, t):\\n    if y.ndim == 1:\\n        t = t.reshape(1, t.size)\\n        y = y.reshape(1, y.size)\\n        \\n    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\\n    if t.size == y.size:\\n        t = t.argmax(axis=1)\\n             \\n    batch_size = y.shape[0]\\n    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\\n\\ndef sigmoid_grad(x):\\n    return (1.0 - sigmoid(x)) * sigmoid(x)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahcKD5z4Kez"
      },
      "source": [
        "# twolayernet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "B3ucUww14HW4",
        "outputId": "309a5b65-1a75-437c-b6f0-9c6c0d3735bc"
      },
      "source": [
        "\"\"\"\n",
        "from function import *\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "    \n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "        \n",
        "        return y\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        \n",
        "        return cross_entropy_error(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "        \n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "        \n",
        "    def gradient(self, x, t):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "        grads = {}\n",
        "        \n",
        "        batch_num = x.shape[0]\n",
        "        \n",
        "        # forward\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "        \n",
        "        # backward\n",
        "        dy = (y - t) / batch_num\n",
        "        grads['W2'] = np.dot(z1.T, dy)\n",
        "        grads['b2'] = np.sum(dy, axis=0)\n",
        "        \n",
        "        da1 = np.dot(dy, W2.T)\n",
        "        dz1 = sigmoid_grad(a1) * da1\n",
        "        grads['W1'] = np.dot(x.T, dz1)\n",
        "        grads['b1'] = np.sum(dz1, axis=0)\n",
        "\n",
        "        return grads\n",
        "\"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom function import *\\n\\nclass TwoLayerNet:\\n\\n    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\\n        # 가중치 초기화\\n        self.params = {}\\n        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\\n        self.params['b1'] = np.zeros(hidden_size)\\n        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\\n        self.params['b2'] = np.zeros(output_size)\\n\\n    def predict(self, x):\\n        W1, W2 = self.params['W1'], self.params['W2']\\n        b1, b2 = self.params['b1'], self.params['b2']\\n    \\n        a1 = np.dot(x, W1) + b1\\n        z1 = sigmoid(a1)\\n        a2 = np.dot(z1, W2) + b2\\n        y = softmax(a2)\\n        \\n        return y\\n        \\n    # x : 입력 데이터, t : 정답 레이블\\n    def loss(self, x, t):\\n        y = self.predict(x)\\n        \\n        return cross_entropy_error(y, t)\\n    \\n    def accuracy(self, x, t):\\n        y = self.predict(x)\\n        y = np.argmax(y, axis=1)\\n        t = np.argmax(t, axis=1)\\n        \\n        accuracy = np.sum(y == t) / float(x.shape[0])\\n        return accuracy\\n        \\n    # x : 입력 데이터, t : 정답 레이블\\n    def numerical_gradient(self, x, t):\\n        loss_W = lambda W: self.loss(x, t)\\n        \\n        grads = {}\\n        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\\n        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\\n        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\\n        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\\n        \\n        return grads\\n        \\n    def gradient(self, x, t):\\n        W1, W2 = self.params['W1'], self.params['W2']\\n        b1, b2 = self.params['b1'], self.params['b2']\\n        grads = {}\\n        \\n        batch_num = x.shape[0]\\n        \\n        # forward\\n        a1 = np.dot(x, W1) + b1\\n        z1 = sigmoid(a1)\\n        a2 = np.dot(z1, W2) + b2\\n        y = softmax(a2)\\n        \\n        # backward\\n        dy = (y - t) / batch_num\\n        grads['W2'] = np.dot(z1.T, dy)\\n        grads['b2'] = np.sum(dy, axis=0)\\n        \\n        da1 = np.dot(dy, W2.T)\\n        dz1 = sigmoid_grad(a1) * da1\\n        grads['W1'] = np.dot(x.T, dz1)\\n        grads['b1'] = np.sum(dz1, axis=0)\\n\\n        return grads\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FQ_IbCCwp4a"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPZkeaHZ5jq_"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from twolayernet import TwoLayerNet\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzztjqAV5wQ1"
      },
      "source": [
        "(x_train, t_train), (x_test, t_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_BY6cU680i4"
      },
      "source": [
        "t_train = to_categorical(t_train)\n",
        "t_test = to_categorical(t_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OaParkK326c"
      },
      "source": [
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size=10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQA6efW4Y0e"
      },
      "source": [
        "# 하이퍼파라미터\n",
        "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100   # 미니배치 크기\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeJpoudZ5qS1"
      },
      "source": [
        "input_size = x_train.shape[1] * x_train.shape[2]\n",
        "x_train = np.reshape(x_train, [-1, input_size])\n",
        "x_test = np.reshape(x_test, [-1, input_size])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YyNXFEw4bjR",
        "outputId": "991a3a8a-1378-4f75-929d-1a4f7ef8c1ab"
      },
      "source": [
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 1에폭당 반복 수\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # 미니배치 획득\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 기울기 계산\n",
        "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "    \n",
        "    # 매개변수 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "    \n",
        "    # 학습 경과 기록\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    # 1에폭당 정확도 계산\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc, test acc | 0.1178, 0.1183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/function.py:24: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc, test acc | 0.8603833333333334, 0.8643\n",
            "train acc, test acc | 0.8647333333333334, 0.8659\n",
            "train acc, test acc | 0.86185, 0.8676\n",
            "train acc, test acc | 0.8555166666666667, 0.8591\n",
            "train acc, test acc | 0.8752, 0.8814\n",
            "train acc, test acc | 0.8603833333333334, 0.8647\n",
            "train acc, test acc | 0.87295, 0.8741\n",
            "train acc, test acc | 0.8519666666666666, 0.8558\n",
            "train acc, test acc | 0.8560333333333333, 0.8591\n",
            "train acc, test acc | 0.87785, 0.8784\n",
            "train acc, test acc | 0.8587, 0.8617\n",
            "train acc, test acc | 0.8544, 0.8543\n",
            "train acc, test acc | 0.85145, 0.8535\n",
            "train acc, test acc | 0.87665, 0.8809\n",
            "train acc, test acc | 0.8647666666666667, 0.8637\n",
            "train acc, test acc | 0.8643166666666666, 0.8666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yr0sR_Ui9R0z",
        "outputId": "4caad6df-b281-4f96-ae85-926d079b32ee"
      },
      "source": [
        "# 그래프 그리기\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, label='train acc')\n",
        "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}